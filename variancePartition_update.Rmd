---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

```{r eval=FALSE, include=FALSE}
# BiocManager::install("variancePartition")
```


```{r echo=FALSE, warning=FALSE}
library("variancePartition")
library(tidyverse)
#https://bioconductor.org/packages/release/bioc/vignettes/variancePartition/inst/doc/variancePartition.html

info_full <- read.csv("output/covs_gds.csv") %>% 
  mutate(weight=ifelse(BWeight < 10, BWeight*1000, BWeight)) 

# https://support.bioconductor.org/p/129082/
# scale numeric covariates on a similar scale as the other factor variables
info_scale <- scale(info_full[, c(4:6, 8:9, 11, 13, 15:18, 21:26)])
info <- cbind(info_full[, c(1, 2, 7, 10, 14, 19, 20)], info_scale) %>% 
  remove_rownames() %>% 
  column_to_rownames(var="RNA_sampleID") %>% 
  mutate_at("treatment", factor)

write.csv(info, file="output/meta_scale.csv")
```

Assess correlation between all pairs of variables
```{r echo=FALSE}
form <- ~ Subject_ID + Visit + sex + treatment + other_covariates

# Compute Canonical Correlation Analysis (CCA)
# between all pairs of variables
# returns absolute correlation value
C <- canCorPairs(form, info)

# Plot correlation matrix
par(mar=c(1,1,1,1))
# between all pairs of variables
plotCorrMatrix(C)
```
High colinearity between variables (Subject and other variables)

# Specify variables to consider
# Age is continuous so model it as a fixed effect
# Individual and Tissue are both categorical,
# so model them as random effects
# Note the syntax used to specify random effects

Detecting problems caused by collinearity of variables
```{r echo=FALSE}
library("DESeq2")
#DESeq2
load("output/gene_anno.RData") 
geneCounts <- naps[, -(1:3)]

# create DESeq2 object from gene-level counts and metadata
dds <- DESeqDataSetFromMatrix(
  countData = geneCounts,
  colData = info,
  design = ~1
)

# Estimate library size correction scaling factors
dds <- estimateSizeFactors(dds)

# identify genes that pass expression cutoff
isexpr <- rowSums(fpm(dds) > 1) >= 0.25 * ncol(dds)

# compute log2 Fragments Per Million
# Alternatively, fpkm(), vst() or rlog() could be used
quantLog <- log2(fpm(dds)[isexpr, ] + 1)

form <- ~ (1|Subject_ID) + (1|Visit) + (1|sex) + (1|treatment) + covariates

# fit model
res <- fitVarPartModel(quantLog[1:4,], form, info)
colinearityScore(res[[1]])
```


"Categorical variables should (almost) always be modeled as a random effect. The difference between modeling a categorical variable as a fixed versus random effect is minimal when the sample size is large compared to the number of categories (i.e. levels). ... So to be on the safe side, categorical variable should be modeled as a random effect."


Removing batch effects before fitting model

"Depending on the size of the batch effect, I have found it useful to correct for the batch effect first and then perform a variancePartitionanalysis afterward."
```{r echo=FALSE}
# extract residuals directly without storing intermediate results
residList <- fitVarPartModel(quantLog, ~ RIN + RNA_conc + (1 | sequence_pool), info,
  fxn = residuals
)

# convert list to matrix
residMatrix <- do.call(rbind, residList)

form <- ~ (1|Subject_ID) + (1|Visit) + (1|sex) + (1|treatment) + numeric_variables

# fit residuals to model
varPart <- fitExtractVarPartModel(residMatrix, form, info)

vp <- sortCols(varPart)

# Figure 1a
# Bar plot of variance fractions for the first 10 genes
plotPercentBars(vp[1:10, ])
```


```{r echo=FALSE}
# Figure 1b
# violin plot of contribution of each variable to total variance
plotVarPart(vp)
```
